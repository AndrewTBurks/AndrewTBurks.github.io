(window.webpackJsonp=window.webpackJsonp||[]).push([[0],{13:function(e){e.exports=[{name:"VisSnippets: A Web-based System for Impromptu Collaborative Data Exploration on Large Displays",abstract:"The VisSnippets system is designed to facilitate effective collaborative data exploration. VisSnippets leverages SAGE2 middleware that enables users to manage the display of digital media content on large displays, thereby providing collaborators with a high-resolution common workspace. Based in JavaScript, the system provides users with the flexibility to implement and/or select visualization packages and to quickly access data in the cloud. By simplifying the application runtime and document manipulation, VisSnippets removes the need to scaffold and integrate interactive visualization applications by hand. Users write reusable blocks of code for data retrieval, transformation, and visualization. By composing various data pipelines from the groups collective 'snippet' pool, users can quickly execute and explore complementary or contrasting visualizations. By giving users the ability to explore alternative scenarios, VisSnippets facilitates parallel work for collaborative data exploration leveraging large-scale displays. We describe the system, provide implementation examples and evaluate it through expert interviews.",team:"A. Burks, L. Renambot, A. Johnson",image:"VisSnippets_Teaser.jpg",award:"",link:"",github:"",paper:""},{name:"SAGE2 + JupyterLab Integration",abstract:"To better integrate existing data science workflows into the SAGE2 collaborative experience, we provide a SAGE2 plugin for JupyterLab. The plugin supports sharing both static notebooks, as well as dynamically updating cell content to SAGE2. A user simply connects to one or more SAGE2 server by URL, and can start sharing their Jupyter Notebook content. Shared notebooks are rendered by Jupyter nbviewer as static web-pages on the SAGE2 wall. Shared notebook cell image output is sent as an image to SAGE2 and dynamically updates every time that a cell is run.",team:"A. Burks, L. Renambot",image:"JupyterLab_SAGE2.jpg",award:"",link:"https://www.youtube.com/watch?v=l2pRLhw6GSE",github:"https://github.com/AndrewTBurks/jupyterlab_sage2",paper:""},{name:"Details-First, Show Context, Overview Last: Supporting Exploration of Viscous Fingers in Large-Scale Ensemble Simulations",abstract:"Visualization research often seeks designs that first establish an overview of the data, in accordance to the information seeking mantra: \u201cOverview first, zoom and filter, then details on demand\u201d. However, in computational fluid dynamics (CFD), as well as in other domains, there are many situations where such a spatial overview is not relevant or practical for users, for example when the experts already have a good mental overview of the data, or when an analysis of a large overall structure may not be related to the specific, information-driven tasks of users. Using scientific workflow theory and, as a vehicle, the problem of viscous finger evolution, we advocate an alternative model that allows domain experts to explore features of interest first, then explore the context around those features, and finally move to a potentially unfamiliar summarization overview. In a model instantiation, we show how a computational back-end can identify and track over time low-level, small features, then be used to filter the context of those features while controlling the complexity of the visualization, and finally to summarize and compare simulations. We demonstrate the effectiveness of this approach with an online web-based exploration of a total volume of data approaching half a billion seven-dimensional data points, and report supportive feedback provided by domain experts with respect to both the instantiation and the theoretical model.",team:"T. Luciani, A. Burks, C. Sugiyama, J. Komperda, G. E. Marai",image:"InteractiveExploration.jpg",award:"Certificate of Merit - IEEE SciVis Contest 2016",link:"https://andrewtburks.com/SciVis2016/",github:"",paper:"detailsfirst_ieee2018.pdf"},{name:"Context-Aware Visualization of Englewood Social Services",abstract:"The Englewood Data Hub (EDH) is a project that brings together both crowdsourced and public data surrounding the Englewood area into a single place.<br>The EDH Resource Directory makes use of the crowdsourced service and school data to display an interactive map with their locations. Its user interface (UI) allows for an exploratory experience that offers filtering of services by names and type and displays detailed information about the services available in Englewood.<br>The EDH Analytics Tool combines the crowdsourced service and school data with public data sets to display visualizations; specifically, the public datasets used are 2010 Census data along with Vacant Lot and Crime data from the Chicago Data Portal.<br>The Englewood Data Hub has been developed by a group of researchers at the Electronic Visualization Laboratory, University of Illinois at Chicago under the direction of Prof. G. Elisabeta Marai.<br>Team members include EVL research experience undergraduate students (REUs): Andrew Burks, Joshua Castor, and Isabel Lindmae.<br>This project is funded by the The Joseph and Bessie Feinberg Foundation and the University of Illinois at Chicago.",team:"A. Burks, J. Castor, I. Lindmae, J. Feinberg, G. E. Marai",image:"EnglewoodFinder.png",award:"",link:"https://englewooddatahub.org",github:"https://github.com/uic-evl/EnglewoodSocialServices/",paper:""},{name:"Dynamic Influence Networks for Rule-Based Models",abstract:"We introduce the Dynamic Influence Network (DIN), a novel visual analytics technique for representing and analyzing rule-based models of protein-protein interaction networks. Rule-based modeling has proved instrumental in developing biological models that are concise, comprehensible, easily extensible, and that mitigate the combinatorial complexity of multi-state and multi-component biological molecules. Our technique visualizes the dynamics of these rules as they evolve over time. Using the data produced by KaSim, an open source stochastic simulator of rule-based models written in the Kappa language, DINs provide a node-link diagram that represents the influence that each rule has on the other rules. That is, rather than representing individual biological components or types, we instead represent the rules about them (as nodes) and the current influence of these rules (as links). Using our interactive DIN-Viz software tool, researchers are able to query this dynamic network to find meaningful patterns about biological processes, and to identify salient aspects of complex rule-based models. To evaluate the effectiveness of our approach, we investigate a simulation of a circadian clock model that illustrates the oscillatory behavior of the KaiC protein phosphorylation cycle.",team:"A. G. Forbes, A. Burks, K. Lee, X. Li, P. Boutillier, J. Krivine, and W. Fontana",image:"DIN.png",award:"",link:"https://creativecodinglab.github.io/DynamicInfluenceNetworks/",github:"https://github.com/CreativeCodingLab/DynamicInfluenceNetworks",paper:"BURKS-LEE-2017- IEEE_TVCG 08017593-small.pdf"},{name:"SAGE2 Partitions",abstract:"While SAGE2 allows users the complete freedom to organize their content, SAGE2 Partitions aim to provide optional structure to the organization. SAGE2 partitions can act as divisions of the screen space, deforming their neighbors when resized. The Partitions can be 'un-snapped' to allow for free movement, becoming a simple grouping of applications. Partitions can be 'tiled' organizing the content within into a grid. As content is added or removed from a Partiton, the groupings are dynamically updated and content dynamically rearranged. Click-and-drag interaction can be used both to create new Partitions in an empty space and essentially select apps to grab, or to 'cut' existing Partitions to divide the size and content.",team:"A. Burks, L. Renambot",image:"PartitionsSmall.jpg",award:"",link:"",github:"",paper:""},{name:"SMART UI",abstract:" We present the design and evaluation of an integrated problem solving environment for cancer therapy analysis. The environment intertwines a statistical martingale model and a K Nearest Neighbor approach with visual encodings, including novel interactive nomograms, in order to compute and explain a patient's probability of survival as a function of similar patient results. A coordinated views paradigm enables exploration of the multivariate, heterogeneous and few-valued data from a large head and neck cancer repository. A visual scaffolding approach further enables users to build from familiar representations to unfamiliar ones.",team:"G. E. Marai, C. Ma, A. Burks, F. Pellolio, G. Canahuate, D. Vock, A. S. R. Mohamed, and C. D. Fuller",image:"SMARTer.png",award:"",link:"http://chihuama.com/SMARTER/",github:"",paper:""},{name:"EnsembleProb",abstract:"We present a web-based visual analysis tool for the exploration of peak distributions over state space and simulation time in such stochastic networks, and the comparison of peak distributions between multiple simulations. Our approach combines multiple linked views to capture ensemble time-evolving probability landscapes. A peak trajectory cube provides users an overview of peak spatiotemporal distributions between six simulations. A peak projection map shows the exact peak locations of multiple simulations at the user selected time. At a more detailed level, users can inspect a particular state in the peak projection map to view for each simulation both the probability values over time, and the local probability landscape shapes. This information is displayed in a small multiple using two glyphs: profile glyphs and arrow glyphs. The arrow glyph indicates that a state is a peak when all the glyph eight arrows point towards the glyph center.",team:"C. Ma, A. Burks, T. Luciani, A. Terebus, J. Liang, and G. E. Marai",image:"EnsembleProb.png",award:"",link:"http://chihuama.com/EnsembleProb/prototype",github:"",paper:""},{name:"Multi-scale Voronoi-based ACT Assessment",abstract:"Our contest submission aimed to develop a static visual representation that shows how geographic and seasonal changes in the availability of the ACT test affects nearby or adjacent testing sites, by moving students or assessments, changing dates, or some other strategy. The Voronoi visualization (Top Middle) encodes test center distribution at regional level (Illinois) by partitioning each region based on distances to test centers. The Voronoi cell intensity is mapped to Assigned/Capacity; the darker the cell, the higher demand in that region.",team:"T. Luciani, J. Trelles, C. Ma, A. Burks, M. M. Thomas, K. Bharadwaj, S. Singh, P. Hanula, L. Di and G. E. Marai.",image:"VGTC-data-contest.png",award:"Honorable Mention - IEEE VGTC VPG Contest 2016",link:"http://vacommunity.org/ieeevpg/viscontest/2016/entries/3.html",github:"",paper:""}]},14:function(e){e.exports={conference:[{name:"Details-First, Show Context, Overview Last: Supporting Exploration of Viscous Fingers in Large-Scale Ensemble Simulations",teamBefore:"T. Luciani, ",teamAfter:", C. Sugiyama, J. Komperda, G.E. Marai",journal:"IEEE Transactions on Visualization and Computer Graphics (Proc. SciVis'18), vol 25, no 1, pp. 1-11, January 2019.",award:"Certificate of Merit - IEEE SciVis Contest 2016"},{name:"Dynamic influence networks for rule-based models",teamBefore:"A. G. Forbes, ",teamAfter:", K. Lee, X. Li, P. Boutillier, J. Krivine, and W. Fontana",journal:"IEEE Transactions on Visualization and Computer Graphics (Proc. VAST'17), 24(1), January 2018.",award:""}],journal:[{name:"Precision Risk Analysis of Cancer Therapy with Interactive Nomograms and Survival Plots",teamBefore:"G. E. Marai, C. Ma, ",teamAfter:", et al.",journal:"IEEE Transactions on Visualization and Computer Graphics, vol. 14, pp. 1-11, March 2018.",award:""}],poster:[{name:"MC2 - Mining Factory Pollution Data through a Spatial-Nonspatial Flow Approach",teamBefore:"J. Castor, J. Borowicz, ",teamAfter:", M. Thomas, T. Luciani, G.E. Marai",journal:"IEEE Visual Analytics Science and Technology (VAST) Challenge 2017 Proceedings, pp. 1-2, 2017.",award:"Honorable Mention - Clarity in Visual Communication"},{name:"MC3 - A Web-Based Interactive Image Explorer for Temporal Analysis of Satellite Images",teamBefore:"V. Mahida, B. Kupiec, ",teamAfter:", T. Luciani, G.E. Marai",journal:"IEEE Visual Analytics Science and Technology (VAST) Challenge 2017 Proceedings, pp. 1-2, 2017.",award:"Honorable Mention - Good Interactive Image Explorer"},{name:"MC1 - A Bespoke Analysis Tool for Spatio-temporal Park Traffic Data",teamBefore:"D. Kirilov, I. Lindmae, ",teamAfter:", C. Ma, G.E. Marai",journal:" IEEE Visual Analytics Science and Technology (VAST) Challenge 2017 Proceedings, pp. 1-2, 2017.",award:""},{name:"Visualizing ensemble time-evolving probability landscapes of stochastic networks",teamBefore:"C. Ma, ",teamAfter:", T. Luciani, A. Terebus, J. Liang, and G. E. Marai",journal:"ISMB/ECCB 2017, pp. 1-2, BioVis\u201917",award:""},{name:"Multi-scale Voronoi-based ACT Assessment",teamBefore:"T. Luciani, J. Trelles, C. Ma, ",teamAfter:", M. M. Thomas, K. Bharadwaj, S. Singh, P. Hanula, L. Di and G. E. Marai.",journal:"IEEE VGTC VPG International Data-Visualization Contest, Baltimore, MD, USA, October 2016.",award:"Honorable Mention"},{name:"Spatial Analysis of Employee Safety Using Organizable Event Quiltmaps",teamBefore:"D. McNamara, J. Tapia, C. Ma, T. Luciani, ",teamAfter:", J. Trelles, and G. E. Marai",journal:"In Proceedings of the IEEE VIS 2016 Workshop on Temporal & Sequential Event Analysis, Baltimore, MD, USA, October 2016.",award:""}]}},17:function(e,a,t){e.exports=t(63)},22:function(e,a,t){},32:function(e,a,t){},34:function(e,a,t){},63:function(e,a,t){"use strict";t.r(a);var n=t(0),i=t.n(n),o=t(7),r=t.n(o),l=(t(22),t(8)),s=t(9),c=t(15),m=t(10),p=t(16),d=(t(6),t(32),t(2));t(34);function u(e){var a=e.type,t=void 0===a?"":a,n=e.style,o=void 0===n?{}:n,r=Object(d.a)(e,["type","style"]);return i.a.createElement("div",{className:"Typography ".concat(t," ").concat(r.className?r.className:""),style:o},r.children)}function h(e){var a=e.title,t=void 0===a?"Navbar":a,n=e.links,o=void 0===n?[]:n,r=e.location,l=void 0===r?"home":r,s=Object(d.a)(e,["title","links","location"]).navigate;return i.a.createElement("div",{className:"navbar"},i.a.createElement("div",{className:"title"},t),o.map(function(e){return i.a.createElement(c,Object.assign({key:e.name},e))}));function c(e){var a=e.name,t=e.to;Object(d.a)(e,["name","to"]);return i.a.createElement("div",{className:"link"+(t===l?" selected":""),onClick:function(){return s(t)}},i.a.createElement(u,null,a))}}function g(){return i.a.createElement("div",{className:"footer"},i.a.createElement(u,{type:"caption"},"Designed by Andrew Burks"),i.a.createElement("a",{className:"link",href:"https://twitter.com/AndrewTBurks/",target:"_blank",rel:"noopener noreferrer"},i.a.createElement(u,{type:"link"},i.a.createElement("i",{className:"fab fa-twitter",style:{marginRight:"5px"}}),"Twitter")),i.a.createElement("a",{className:"link",href:"https://github.com/AndrewTBurks/",target:"_blank",rel:"noopener noreferrer"},i.a.createElement(u,{type:"link"},i.a.createElement("i",{className:"fab fa-github",style:{marginRight:"5px"}}),"GitHub")),i.a.createElement("a",{className:"link",href:"/content/CV_Andrew_Burks_Dec13.pdf",target:"_blank",rel:"noopener noreferrer"},i.a.createElement(u,{type:"link"},i.a.createElement("i",{className:"far fa-file-pdf",style:{marginRight:"5px"}}),"Curriculum Vitae")))}function f(e){return i.a.createElement("div",{className:"modal-overlay",onClick:e.onClose,style:{opacity:e.open?1:0,pointerEvents:e.open?"all":"none"}},i.a.createElement("div",{className:"modal",onClick:function(e){e.stopPropagation()}},i.a.createElement("div",{className:"closeButton",onClick:e.onClose},i.a.createElement("i",{className:"fa-2x fas fa-times"})),e.children))}var b=t(12),y=Object(b.unstable_createResource)(function(e){return new Promise(function(a){var t=new Image;t.src=e,t.onload=a})});function v(e){var a=e.src,t=e.alt,n=Object(d.a)(e,["src","alt"]);return y.read(a),i.a.createElement("img",Object.assign({src:a,alt:t},n))}var E=t(1),w=t.n(E);function k(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",{className:"panel"},i.a.createElement("div",{className:"panel-section"},i.a.createElement(i.a.Suspense,{fallback:i.a.createElement("div",{style:{display:"flex",alignItems:"center",justifyContent:"center",width:"100%",flexDirection:"column",height:"100%"}},i.a.createElement(w.a,{type:"Triangle",color:"var(--purple)",height:"100",width:"100"}))},i.a.createElement(v,{src:"/img/Profile.jpg",alt:"Me",style:{maxWidth:"100%",maxHeight:"500px",border:"1px solid var(--gray)"}}))),i.a.createElement("div",{className:"panel-section text"},i.a.createElement(u,{type:"heading special"},"I'm Andrew Burks."),i.a.createElement(u,{type:"default"},"I am a Ph.D. Computer Science student at the University of Illinois at Chicago. I am currently a Research Assistant at the Electronic Visualization Laboratory at UIC. I have experience working on research projects related to data visualization and the development of collaborative software for large/tiled displays."),i.a.createElement(u,{type:"default"},"My current research interests are Collaborative Visualization and Data Exploration."))))}function A(e){var a=e.info,t=a.team.split("A. Burks");return i.a.createElement("div",{className:"project-modal-wrapper"},i.a.createElement(u,{type:"heading",style:{fontWeight:"normal"}},a.name),i.a.createElement(u,{type:"award-large"},a.award),i.a.createElement(u,{type:"subsubheading"},t[0],i.a.createElement("strong",null,"A. Burks"),t[1]),i.a.createElement(i.a.Suspense,{fallback:i.a.createElement("div",{style:{display:"flex",alignItems:"center",justifyContent:"center",width:"100%"}},i.a.createElement(w.a,{type:"Triangle",color:"var(--purple)",height:"100",width:"100"}))},i.a.createElement(v,{src:"/img/"+a.image,alt:a.name,style:{width:"100%",margin:"5px 0",border:"1px solid var(--gray)"}})),a.abstract.split("<br>").map(function(e){return i.a.createElement(u,{key:e,type:"default",style:{textAlign:"justify",textIndent:"50px"}},e)}))}function S(e){var a=e.info;return i.a.createElement("div",{className:"card",onClick:function(){return e.showModal(i.a.createElement(A,e))}},i.a.createElement("div",{className:"title"},i.a.createElement(u,{type:"caption"},a.name),a.award&&i.a.createElement(u,{type:"award"},a.award)),i.a.createElement("div",{className:"image"},i.a.createElement(i.a.Suspense,{fallback:i.a.createElement("div",{style:{display:"flex",alignItems:"center",justifyContent:"center",width:"100%"}},i.a.createElement(w.a,{type:"Triangle",color:"var(--purple)",height:"100",width:"100"}))},i.a.createElement(v,{src:"/img/"+a.image,alt:a.name,style:{height:"100%"}}))),i.a.createElement(u,{className:"links"},a.link&&i.a.createElement("a",{href:a.link,target:"_blank",rel:"noopener noreferrer",onClick:function(e){e.stopPropagation()}},i.a.createElement(u,{type:"link"},i.a.createElement("i",{className:"fas fa-link",style:{marginRight:"5px"}}),"Link")),a.github&&i.a.createElement("a",{href:a.github,target:"_blank",rel:"noopener noreferrer",onClick:function(e){e.stopPropagation()}},i.a.createElement(u,{type:"link"},i.a.createElement("i",{className:"fab fa-github",style:{marginRight:"5px"}}),"Repo")),a.paper&&i.a.createElement("a",{href:"/content/"+a.paper,target:"_blank",rel:"noopener noreferrer",onClick:function(e){e.stopPropagation()}},i.a.createElement(u,{type:"link"},i.a.createElement("i",{className:"fas fa-scroll",style:{marginRight:"5px"}}),"Paper"))))}function C(e){var a=e.projects;return i.a.createElement(i.a.Fragment,null,a.map(function(a){return i.a.createElement(S,{key:a.name,info:a,showModal:e.showModal})}))}function x(e){return i.a.createElement("div",null,i.a.createElement(u,{type:"heading",style:{fontWeight:"normal",fontSize:"24px"}},e.title),e.pubs.map(function(e){return i.a.createElement("div",{key:e.name},i.a.createElement(u,{type:"publication"},e.teamBefore,i.a.createElement("strong",null,"A. Burks"),e.teamAfter,". ",e.name,". ",e.journal),i.a.createElement(u,{type:"award"},e.award))}))}function T(e){var a=e.pubs,t=a.conference,n=a.journal,o=a.poster;return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",{className:"panel"},i.a.createElement("div",{className:"panel-section text"},i.a.createElement(x,{title:"Conference Papers",pubs:t}),i.a.createElement(x,{title:"Journal Articles",pubs:n}),i.a.createElement(x,{title:"Short Papers, Posters & Abstracts",pubs:o}))))}function M(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",{className:"panel"},i.a.createElement("div",{className:"panel-section text"},i.a.createElement(u,{type:"heading special"},"About Me"),i.a.createElement(u,{type:"subheading"},"My Work"),i.a.createElement(u,{type:"default"},"Through my work, I have gained hands-on experience in two main areas:",i.a.createElement("strong",null," ","Data Visualization and Visual Analytics, and Human Computer Interaction"),'. Broadly, I am interested in the role of visualization and "human-data" interfaces in analytical processes and workflows.'),i.a.createElement(u,{type:"default"}),i.a.createElement(u,{type:"default"},"In the data visualization research in which I participated, I applied domain-agnostic design to visualization projects across domain science, social good, and operational workflow support. My science-supporting visualization research was carried out across a broad range of scientific domains from computational fluid dynamics (CFD), to biology and precision medicine, to high-capacity networking instrumentation."),i.a.createElement(u,{type:"default"},i.a.createElement("strong",null,i.a.createElement("span",{style:{color:"#0EB87A"}},"SAGE2\u2122")," - Scalable Amplified Group Environment"),' is an NSF $5M project to build a web-based system for tiled display walls to enhance data intensive co-located and remote collaboration. My research in SAGE2 focuses on providing expressive support to collaborative data exploration workflows. My first two projects were an application for visualizing arbitrary Comma-Separated Value (CSV) formatted data, and a layout system which supports the application of geometric layout constraints to digital content in the freeform collaborative workspace. My current research focuses on supporting data exploration within the SAGE2 workspace. To this end, I have created a JupyterLab extension allowing users to display notebooks and reactive notebook cells in SAGE2. To build native support into SAGE2 for the exploratory analysis seen in Jupyter Notebooks, I designed and implemented the "VisSnippets" system in SAGE2. Supporting impromptu collaborative data exploration, VisSnippets allows users to write and compose modular analysis blocks for data retrieval, transformation/analysis, and visualization into branching data pipelines.'),i.a.createElement(u,{type:"subheading"},"Honors and Awards"),i.a.createElement(u,{type:"default",style:{display:"flex",flexDirection:"row",alignItems:"center",justifyContent:"stretch"}},i.a.createElement("div",{style:{flex:0,padding:"5px 20px"}},"2017"),i.a.createElement("div",{style:{flex:1}},i.a.createElement("div",null,i.a.createElement("div",{type:"default"},i.a.createElement("strong",null,"Honorable Mention - Clarity in Visual Communication"),", IEEE VIS 2017 VAST Challenge Mini-Challenge 2."),i.a.createElement(u,{type:"caption"},"Phoenix, AZ.")),i.a.createElement("div",null,i.a.createElement("div",{type:"default"},i.a.createElement("strong",null,"Honorable Mention - Good Interactive Image Explorer"),", IEEE VIS 2017 VAST Challenge Mini-Challenge 3."),i.a.createElement(u,{type:"caption"},"Phoenix, AZ.")))),i.a.createElement(u,{type:"default",style:{display:"flex",flexDirection:"row",alignItems:"center",justifyContent:"stretch"}},i.a.createElement("div",{type:"default",style:{flex:0,padding:"5px 20px"}},"2016"),i.a.createElement("div",{style:{flex:1}},i.a.createElement("div",null,i.a.createElement("div",{type:"default"},i.a.createElement("strong",null,"Honorable Mention"),", IEEE VIS Conference: VGTC VPG Data Visualization Contest."),i.a.createElement(u,{type:"caption"},"Baltimore, MD.")))))))}var I=t(13),V=t(14);function B(e){var a=e.location,t={home:i.a.createElement(k,null),about:i.a.createElement(M,null),projects:i.a.createElement(C,{projects:I,showModal:e.showModal}),publications:i.a.createElement(T,{pubs:V})};return i.a.createElement("div",{className:"contentWrapper"},t[a])}var j=[{name:"Home",to:"home"},{name:"Projects",to:"projects"},{name:"Publications",to:"publications"},{name:"About",to:"about"}],G=function(e){function a(){var e,t;Object(l.a)(this,a);for(var n=arguments.length,i=new Array(n),o=0;o<n;o++)i[o]=arguments[o];return(t=Object(c.a)(this,(e=Object(m.a)(a)).call.apply(e,[this].concat(i)))).state={modalOpen:!1,modalChild:null,page:"home"},t.showModal=function(e){t.setState({modalOpen:!0,modalChild:e})},t.closeModal=function(){t.setState({modalOpen:!1})},t.changePage=function(e){t.setState({page:e})},t}return Object(p.a)(a,e),Object(s.a)(a,[{key:"render",value:function(){return i.a.createElement("div",{className:"App"},i.a.createElement(h,{title:"Andrew Burks",links:j,location:this.state.page,navigate:this.changePage}),i.a.createElement(B,{showModal:this.showModal,location:this.state.page}),i.a.createElement(g,null),i.a.createElement(f,{open:this.state.modalOpen,onClose:this.closeModal},this.state.modalChild))}}]),a}(n.Component);Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));r.a.render(i.a.createElement(i.a.StrictMode,null,i.a.createElement(G,null)),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then(function(e){e.unregister()})}},[[17,2,1]]]);
//# sourceMappingURL=main.77b9446e.chunk.js.map